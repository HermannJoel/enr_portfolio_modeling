{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fc85e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------------+-------------------+-----+-----+----+------------------+------------------+\n",
      "|asset_id|projet_id|         projet|               date|année| trim|mois|           p50_adj|           p90_adj|\n",
      "+--------+---------+---------------+-------------------+-----+-----+----+------------------+------------------+\n",
      "|       1|     ALBE| Ally Bessadous|2022-01-01 00:00:00| 2022|Q1-22|   1|      2263.8404137|     2064.18931704|\n",
      "|       2|     ALME|  Ally Mercoeur|2022-01-01 00:00:00| 2022|Q1-22|   1|1507.5778515400002|     1374.62255364|\n",
      "|       3|     ALMO|   Ally Monteil|2022-01-01 00:00:00| 2022|Q1-22|   1|     1958.07452628|     1785.38933142|\n",
      "|       4|     ALVE|Ally Verseilles|2022-01-01 00:00:00| 2022|Q1-22|   1|     2370.38912006|     2161.34134268|\n",
      "|       5|     ART1|       Artois 1|2022-01-01 00:00:00| 2022|Q1-22|   1|3848.5022273099994|3606.6227021799996|\n",
      "+--------+---------+---------------+-------------------+-----+-----+----+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- asset_id: integer (nullable = true)\n",
      " |-- projet_id: string (nullable = true)\n",
      " |-- projet: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- année: integer (nullable = true)\n",
      " |-- trim: string (nullable = true)\n",
      " |-- mois: integer (nullable = true)\n",
      " |-- p50_adj: double (nullable = true)\n",
      " |-- p90_adj: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/mnt/d/local-repo-github/enr_portfolio_modeling/')\n",
    "os.chdir('D:/local-repo-github/enr_portfolio_modeling/files-storage/processed')\n",
    "spark=SparkSession.builder.master('spark://pop-os.localdomain:7077').appName('blx-mdp-csv').getOrCreate()\n",
    "\n",
    "df = spark.read.csv('D:/local-repo-github/enr_portfolio_modeling/files-storage/processed/production_asset.csv',\n",
    "                   header=True,inferSchema=True)\n",
    "df.show(5)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7025c9-dcb5-47a4-ae41-f58c932ae4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_spark_df(path:str, n:int)->'DataFrame':\n",
    "    \"\"\"Function to read csv file with spark\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : string\n",
    "        path to csv file\n",
    "    n : integer\n",
    "        number of line to display\n",
    "    Example\n",
    "    -------\n",
    "    >>>read_spark_df(path=\"D:/local-repo-github/enr_portfolio_modeling/files-storage/processed/production_asset.csv\", n=10)\n",
    "    \"\"\"\n",
    "    dataframe = spark\\\n",
    "    .read\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .csv(path).show(n)\n",
    "    return dataframe\n",
    "\n",
    "test=read_spark_df(path=\"D:/local-repo-github/enr_portfolio_modeling/files-storage/processed/contract_prices.csv\", n=10)\n",
    "df.select('projet_id', 'projet').show()\n",
    "\n",
    "df.filter(df['année']<2023).select(['projet_id', 'projet', 'p50_adj']).show()\n",
    "df.filter(df['p50_adj']>4000).show()\n",
    "df.select(df['p50_adj']==2022).show()\n",
    "df.filter(df['p50_adj']<2023).show()\n",
    "u5000=df.filter('p50_adj>5000').collect()\n",
    "u5000[0].asDict()['projet_id']\n",
    "#spark sql\n",
    "df.createOrReplaceTempView('prod')\n",
    "df_over10000=spark.sql('select * from prod where p50_adj > 10000')\n",
    "df_over10000.show()\n",
    "\n",
    "\n",
    "df_over10000.describe('p50_adj').show()\n",
    "df.groupBy('state').count().show()\n",
    "df.agg({'age':'mean'}).show()\n",
    "\n",
    "import pyspark.sql.functions as f\n",
    "df.select(f.collect_set(df['state'])).collect()\n",
    "# Returns a Row of unique states which will be all 50.\n",
    "df.select(f.countDistinct('state').alias('states')).show()\n",
    "#returns a single column named states with a single value of 50.\n",
    "df.select(f.md5('street').alias('hash')).collect()\n",
    "#Returns an md5 hash of the street value for each row\n",
    "# Row(hash='81576976c4903b063c46ed9fdd140d62'),\n",
    "df.select(f.reverse(df.state).alias('state-reverse')).collect()\n",
    "# returns each rows street value reversed\n",
    "# Row(state-reverse='nisnocsiW')\n",
    "select(f.soundex(df.name).alias('soundex')).collect()\n",
    "# returns a soundex of the name field for each row\n",
    "# Row(soundex='P362')\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
