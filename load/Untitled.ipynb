{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fe44c1-c3be-4866-af62-b7acad50951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06130f2b-cbd3-4fe2-a341-5e1f4e9ce1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf, SQLContext \n",
    "from pyspark.sql import SparkSession, Row, functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edddc7e5-9247-4fca-8044-232e2ff57c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Config\n",
    "config_file=os.path.join(os.path.dirname(\"__file__\"), '/mnt/d/local-repo-github/DataEng-Projects/enr_risk_modeling/Config/config.ini') \n",
    "config=configparser.ConfigParser(allow_no_value=True)\n",
    "config.read(config_file)\n",
    "\n",
    "\n",
    "JAVA_HOME = os.path.join(os.path.dirname(\"__file__\"), config['develop']['JAVA_HOME'])\n",
    "pgpass = os.path.join(os.path.dirname(\"__file__\"),config['develop']['pgpass'])\n",
    "pgpuid = os.path.join(os.path.dirname(\"__file__\"),config['develop']['pguid'])\n",
    "pgpuid = os.path.join(os.path.dirname(\"__file__\"),config['develop']['pguid'])\n",
    "postgres_driver = os.path.join(os.path.dirname(\"__file__\"),config['develop']['postgres_driver'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470c4e88-5eab-46da-99dd-900a6dd0bdff",
   "metadata": {},
   "source": [
    "### Extract from Mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300ca088-6496-4637-8ab3-1484205a0410",
   "metadata": {},
   "outputs": [],
   "source": [
    "SparkSession sparkSession = SparkSession.builder() \\\n",
    "    .master('local') \\\n",
    "    .appName('load_to_mongodb') \\\n",
    "    .config(\"spark.mongodb.read.connection.uri\", 'mongodb://localhost:27017/staggingdw/asset') \\\n",
    "    .config(\"spark.mongodb.read.readPreference.name\", \"secondaryPreferred\") \\\n",
    "    .config(\"spark.mongodb.write.connection.uri\", \"mongodb://localhost:27017/staggingdw/asset\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e828c839-e5a3-4674-9a78-c373b6322e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "database = 'dw'\n",
    "collection = 'DimAsset'\n",
    "connectionString = ('mongodb+srv://nherm:24Fe1988@dw.DimAsset.m5dc1ny.mongodb.net/?retryWrites=true&w=majority')\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config('spark.mongodb.input.uri',connectionString) \\\n",
    "    .config('spark.mongodb.input.uri', connectionString) \\\n",
    "    .config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.12:3.0.1') \\\n",
    "    .getOrCreate()\n",
    "# Reading from MongoDB\n",
    "df = spark.read \\\n",
    "    .format(\"com.mongodb.spark.sql.DefaultSource\") \\\n",
    "    .option(\"uri\", connectionString) \\\n",
    "    .option(\"database\", database) \\\n",
    "    .option(\"collection\", collection) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d2ec53-ba7f-4ff5-b229-0a2c0aa8c40f",
   "metadata": {},
   "source": [
    "#### Load to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bcbb52-6d58-4712-adb7-d61b593f5fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(df, tbl):\n",
    "    try:\n",
    "        rows_imported = 0\n",
    "        print(f'importing rows {rows_imported} to {rows_imported + df.count()}... for table {tbl}')\n",
    "        df.write.mode(\"overwrite\") \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", target_url) \\\n",
    "        .option(\"user\", uid) \\\n",
    "        .option(\"password\", pwd) \\\n",
    "        .option(\"driver\", target_driver) \\\n",
    "        .option(\"dbtable\", \"src_\" + tbl) \\\n",
    "        .save()\n",
    "        print(\"Data imported successful\")\n",
    "        rows_imported += df.count()\n",
    "    except Exception as e:\n",
    "        print(\"Data load error: \" + str(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
